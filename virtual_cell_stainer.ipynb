{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b051c2-ed75-4bdf-bbe9-cbfe88ee5e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "print(\"GPUs:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2276e47f-df58-46ce-8d85-2f25157f16c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import glob\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.keras import layers, models\n",
    "import scipy.ndimage as ndimage\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.transform import resize\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import random\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow_addons.layers import SpectralNormalization, InstanceNormalization\n",
    "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, LeakyReLU, BatchNormalization, Flatten, Dense, UpSampling2D, Concatenate, Dropout, Layer, LayerNormalization, MultiHeadAttention, add\n",
    "from tensorflow.keras.layers import concatenate, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.mixed_precision import Policy, set_global_policy\n",
    "from collections import defaultdict\n",
    "\n",
    "# Configure TensorFlow for consistent float32 precision\n",
    "tf.keras.backend.set_floatx('float32')\n",
    "tf.keras.mixed_precision.set_global_policy('float32')\n",
    "\n",
    "# GPU Configuration\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"Using GPU: {gpus[0]}\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "def build_discriminator(input_shape=(128, 128, 2)):\n",
    "    \"\"\"\n",
    "    Constructs a CNN-based discriminator for conditional GAN (cGAN).\n",
    "    \n",
    "    The discriminator takes a concatenated input of brightfield (ch3) and fluorescence (ch1/ch2) \n",
    "    images to distinguish between real and generated fluorescence outputs. Uses progressive \n",
    "    downsampling with batch normalization and LeakyReLU activations.\n",
    "    \n",
    "    Args:\n",
    "        input_shape (tuple): Shape of input tensor (height, width, channels).\n",
    "                           Expected: (128, 128, 2) for concatenated brightfield + fluorescence\n",
    "    \n",
    "    Returns:\n",
    "        Model: Compiled Keras model that outputs a single scalar prediction (real/fake)\n",
    "        \n",
    "    Architecture:\n",
    "        - 4 convolutional blocks with progressive channel increase (32→64→128→256)\n",
    "        - Each block: Conv2D → BatchNorm → LeakyReLU → 2x2 stride downsampling\n",
    "        - Final output: Flattened features → Dense(1) for binary classification\n",
    "        \n",
    "    Note:\n",
    "        Uses float32 dtype explicitly to ensure numerical stability during training.\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=input_shape, dtype='float32')\n",
    "    \n",
    "    # Downsample from 128×128 to 8×8 through progressive convolutions\n",
    "    x = Conv2D(32, (4,4), strides=2, padding='same')(inputs)  # 64×64\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    \n",
    "    x = Conv2D(64, (4,4), strides=2, padding='same')(x)  # 32×32\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    \n",
    "    x = Conv2D(128, (4,4), strides=2, padding='same')(x)  # 16×16\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    \n",
    "    x = Conv2D(256, (4,4), strides=2, padding='same')(x)  # 8×8\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    \n",
    "    # Flatten to 8×8×256 = 16384 features\n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    # Final classification layer for real/fake discrimination\n",
    "    x = Dense(1, dtype='float32')(x)\n",
    "    \n",
    "    return Model(inputs, x)\n",
    "\n",
    "\n",
    "def build_generator(input_shape=(128, 128, 1)):\n",
    "    \"\"\"\n",
    "    Constructs a U-Net style generator for conditional GAN (cGAN).\n",
    "    \n",
    "    Takes brightfield microscopy images (ch3) as input and generates corresponding \n",
    "    fluorescence images for both dead (ch1) and alive (ch2) cell populations. \n",
    "    Uses encoder-decoder architecture with skip connections for preserving spatial details.\n",
    "    \n",
    "    Args:\n",
    "        input_shape (tuple): Shape of input brightfield image (height, width, channels).\n",
    "                           Expected: (128, 128, 1) for single-channel brightfield\n",
    "    \n",
    "    Returns:\n",
    "        Model: Keras model with dual outputs [dead_fluorescence, alive_fluorescence]\n",
    "        \n",
    "    Architecture:\n",
    "        Encoder:\n",
    "        - 3 downsampling blocks: Conv2D → BatchNorm → LeakyReLU\n",
    "        - Progressive channel increase: 32 → 64 → 128\n",
    "        - Spatial reduction: 128×128 → 64×64 → 32×32 → 16×16\n",
    "        \n",
    "        Decoder:\n",
    "        - 3 upsampling blocks: UpSampling2D → Conv2D → BatchNorm → LeakyReLU\n",
    "        - Skip connections from corresponding encoder layers\n",
    "        - Progressive channel decrease with spatial expansion\n",
    "        \n",
    "        Outputs:\n",
    "        - Two separate tanh-activated channels for dead/alive fluorescence\n",
    "        \n",
    "    Design Notes:\n",
    "        - Uses UpSampling2D + Conv2D instead of Conv2DTranspose to avoid checkerboard artifacts\n",
    "        - Bias disabled (use_bias=False) in conv layers paired with BatchNormalization\n",
    "        - Tanh activation ensures output range [-1, 1] matching normalized input data\n",
    "        - Skip connections preserve fine-grained spatial information lost during downsampling\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # Encoder: Progressive downsampling with feature extraction\n",
    "    enc1 = Conv2D(32, (4,4), strides=2, padding='same')(inputs)  # 128→64\n",
    "    enc1 = LeakyReLU(0.2)(enc1)\n",
    "\n",
    "    enc2 = Conv2D(64, (4,4), strides=2, padding='same')(enc1)   # 64→32\n",
    "    enc2 = BatchNormalization()(enc2)\n",
    "    enc2 = LeakyReLU(0.2)(enc2)\n",
    "\n",
    "    enc3 = Conv2D(128, (4,4), strides=2, padding='same')(enc2)  # 32→16\n",
    "    enc3 = BatchNormalization()(enc3)\n",
    "    enc3 = LeakyReLU(0.2)(enc3)\n",
    "\n",
    "    # Decoder: Progressive upsampling with skip connections (U-Net style)\n",
    "\n",
    "    # Upsampling Block 1: 16×16 → 32×32\n",
    "    dec1 = UpSampling2D(size=(2,2))(enc3)\n",
    "    dec1 = Conv2D(256, (3,3), padding='same', use_bias=False)(dec1)\n",
    "    dec1 = BatchNormalization()(dec1)\n",
    "    dec1 = LeakyReLU(0.2)(dec1)\n",
    "    dec1 = concatenate([dec1, enc2])  # Skip connection from encoder\n",
    "\n",
    "    # Upsampling Block 2: 32×32 → 64×64\n",
    "    dec2 = UpSampling2D(size=(2,2))(dec1)\n",
    "    dec2 = Conv2D(128, (3,3), padding='same', use_bias=False)(dec2)\n",
    "    dec2 = BatchNormalization()(dec2)\n",
    "    dec2 = LeakyReLU(0.2)(dec2)\n",
    "    dec2 = concatenate([dec2, enc1])  # Skip connection from encoder\n",
    "\n",
    "    # Upsampling Block 3: 64×64 → 128×128\n",
    "    dec3 = UpSampling2D(size=(2,2))(dec2)\n",
    "    dec3 = Conv2D(64, (3,3), padding='same', use_bias=False)(dec3)\n",
    "    dec3 = BatchNormalization()(dec3)\n",
    "    dec3 = LeakyReLU(0.2)(dec3)\n",
    "\n",
    "    # Dual output heads for dead and alive cell fluorescence channels\n",
    "    out_dead = Conv2D(1, (1,1), padding='same', activation='tanh', use_bias=False, name='gen_output_dead')(dec3)\n",
    "    out_alive = Conv2D(1, (1,1), padding='same', activation='tanh', use_bias=False, name='gen_output_alive')(dec3)\n",
    "\n",
    "    return Model(inputs, [out_dead, out_alive])\n",
    "\n",
    "\n",
    "class ImageProcessor:\n",
    "    \"\"\"\n",
    "    Comprehensive image processing pipeline for microscopy data preparation.\n",
    "    \n",
    "    Handles organization, preprocessing, and tile extraction from multi-channel microscopy \n",
    "    images for deep learning applications. Designed specifically for brightfield (ch3) \n",
    "    and fluorescence (ch1/ch2) microscopy data with position-based organization.\n",
    "    \n",
    "    Key Features:\n",
    "    - Automatic file organization by imaging position and channel\n",
    "    - Train/validation/test splitting at position level (prevents data leakage)\n",
    "    - GPU-accelerated normalization and brightness enhancement\n",
    "    - Binary mask generation for region-of-interest extraction\n",
    "    - Tile extraction around mask centroids for standardized input sizes\n",
    "    \n",
    "    Attributes:\n",
    "        image_path (str): Source directory containing raw TIFF images\n",
    "        output_base (str): Base directory for organized output structure\n",
    "        batch_size (int): Number of files to process per batch\n",
    "        channel_matrices (dict): Storage for organized file paths by channel\n",
    "        device (str): Compute device ('/GPU:0' or '/CPU:0')\n",
    "        split_ratios (tuple): Train/validation/test split ratios\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, image_path, output_base=\"channel_matrix\", batch_size=500, split_ratios=(0.6, 0.2, 0.2)):\n",
    "        \"\"\"\n",
    "        Initialize the ImageProcessor with configuration parameters.\n",
    "        \n",
    "        Args:\n",
    "            image_path (str): Path to directory containing source TIFF images\n",
    "            output_base (str): Base directory for organized output structure\n",
    "            batch_size (int): Files per processing batch (for memory management)\n",
    "            split_ratios (tuple): (train, validation, test) split proportions\n",
    "        \n",
    "        Raises:\n",
    "            ValueError: If split_ratios don't sum to 1.0\n",
    "            FileNotFoundError: If image_path doesn't exist\n",
    "        \"\"\"\n",
    "        self.image_path = image_path\n",
    "        self.output_base = output_base\n",
    "        self.batch_size = batch_size\n",
    "        self.channel_matrices = {\"ch1\": {}, \"ch2\": {}, \"ch3\": {}}\n",
    "        self.device = '/GPU:0' if gpus else '/CPU:0'\n",
    "        self.split_ratios = split_ratios\n",
    "        \n",
    "        # Validate split ratios\n",
    "        if abs(sum(split_ratios) - 1.0) > 1e-6:\n",
    "            raise ValueError(f\"Split ratios must sum to 1.0, got {sum(split_ratios)}\")\n",
    "    \n",
    "\n",
    "    def extract_position_key(self, file_name):\n",
    "        \"\"\"\n",
    "        Extracts standardized position identifier from microscopy filename.\n",
    "        \n",
    "        Parses filenames with format containing row (r), column (c), frame (f), \n",
    "        and position (p) information to create consistent position keys for grouping.\n",
    "        \n",
    "        Args:\n",
    "            file_name (str): Microscopy image filename\n",
    "                           Expected format: *rXcYfZpW-ch*sk*.tiff\n",
    "                           \n",
    "        Returns:\n",
    "            str or None: Position key in format \"rXcYfZpW\" if parsing successful,\n",
    "                        None if filename doesn't match expected pattern\n",
    "                        \n",
    "        Example:\n",
    "            >>> extract_position_key(\"sample_r02c03f001p01-ch1sk1.tiff\")\n",
    "            \"r02c03f001p01\"\n",
    "        \"\"\"\n",
    "        if all(x in file_name for x in [\"r\", \"c\", \"p\", \"-ch\"]):\n",
    "            parts = file_name.split('r')[1].split('c')\n",
    "            row = parts[0]\n",
    "            col_parts = parts[1].split('f')\n",
    "            col = col_parts[0]\n",
    "            f_parts = col_parts[1].split('p')\n",
    "            frame = f_parts[0]\n",
    "            pos = f_parts[1].split('-')[0]\n",
    "            return f\"r{row}c{col}f{frame}p{pos}\"\n",
    "        return None\n",
    "        \n",
    "    def process_file(self, file_name, subset):\n",
    "        \"\"\"\n",
    "        Process and organize a single image file into the appropriate directory structure.\n",
    "        \n",
    "        Extracts metadata from filename, creates organized directory structure by \n",
    "        subset/channel/position, and copies files to appropriate locations. Maintains\n",
    "        channel_matrices tracking for downstream processing.\n",
    "        \n",
    "        Args:\n",
    "            file_name (str): Name of the image file to process\n",
    "            subset (str): Target subset ('train', 'val', or 'test')\n",
    "            \n",
    "        Side Effects:\n",
    "            - Creates directory structure under output_base\n",
    "            - Copies file to organized location\n",
    "            - Updates self.channel_matrices with file path\n",
    "            \n",
    "        Error Handling:\n",
    "            Catches and logs processing errors without stopping batch processing\n",
    "        \"\"\"\n",
    "        try:\n",
    "            position_key = self.extract_position_key(file_name)\n",
    "            if position_key is None:\n",
    "                return\n",
    "                \n",
    "            channel = file_name.split(\"-ch\")[1].split(\"sk\")[0]\n",
    "            row_col = position_key.split('f')[0]  # Get rXcY part\n",
    "            \n",
    "            channel_key = f\"r{row_col.split('r')[1].split('c')[0]}c{row_col.split('c')[1]}\"\n",
    "            file_path = os.path.join(self.image_path, file_name)\n",
    "            \n",
    "            # Create subset-specific directory structure\n",
    "            channel_dir = os.path.join(self.output_base, subset, f\"ch{channel}\", channel_key)\n",
    "            os.makedirs(channel_dir, exist_ok=True)\n",
    "\n",
    "            shutil.copy(file_path, os.path.join(channel_dir, file_name))\n",
    "            self.channel_matrices[f\"ch{channel}\"].setdefault(channel_key, []).append(file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Failed to process file {file_name}: {e}\")\n",
    "\n",
    "    def organize_images(self):\n",
    "        \"\"\"\n",
    "        Organize all images into train/validation/test splits with position-level grouping.\n",
    "        \n",
    "        Prevents data leakage by ensuring all images from the same microscopy position \n",
    "        are placed in the same subset. Uses multithreading for efficient file processing.\n",
    "        \n",
    "        Process:\n",
    "        1. Group files by position identifier (all channels together)\n",
    "        2. Randomly shuffle position groups\n",
    "        3. Split groups according to specified ratios\n",
    "        4. Process files in parallel using ThreadPoolExecutor\n",
    "        \n",
    "        Returns:\n",
    "            dict: Updated channel_matrices containing organized file paths\n",
    "            \n",
    "        Note:\n",
    "            This is crucial for preventing data leakage in microscopy data where\n",
    "            adjacent tiles or different channels from the same position are highly correlated.\n",
    "        \"\"\"\n",
    "        os.makedirs(self.output_base, exist_ok=True)\n",
    "        all_files = [f for f in os.listdir(self.image_path) if f.lower().endswith('.tiff')]\n",
    "        \n",
    "        # Group files by position (all channels for same position together)\n",
    "        position_groups = defaultdict(list)\n",
    "        for file in all_files:\n",
    "            position_key = self.extract_position_key(file)\n",
    "            if position_key:\n",
    "                position_groups[position_key].append(file)\n",
    "        \n",
    "        # Convert to list of groups and shuffle for random split\n",
    "        group_list = list(position_groups.values())\n",
    "        random.shuffle(group_list)\n",
    "        \n",
    "        # Calculate split indices based on position groups\n",
    "        total_groups = len(group_list)\n",
    "        train_end = int(total_groups * self.split_ratios[0])\n",
    "        val_end = train_end + int(total_groups * self.split_ratios[1])\n",
    "        \n",
    "        # Split the groups\n",
    "        train_groups = group_list[:train_end]\n",
    "        val_groups = group_list[train_end:val_end]\n",
    "        test_groups = group_list[val_end:]\n",
    "        \n",
    "        # Flatten the groups into file lists\n",
    "        train_files = [file for group in train_groups for file in group]\n",
    "        val_files = [file for group in val_groups for file in group]\n",
    "        test_files = [file for group in test_groups for file in group]\n",
    "        \n",
    "        print(f\"[INFO] Processing {len(all_files)} files in {total_groups} position groups...\")\n",
    "        print(f\"[INFO] Splitting into: Train ({len(train_files)}), Val ({len(val_files)}), Test ({len(test_files)})\")\n",
    "        \n",
    "        # Process each subset using multithreading for efficiency\n",
    "        with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "            # Process train files\n",
    "            print(\"[INFO] Processing train files...\")\n",
    "            list(tqdm(executor.map(lambda f: self.process_file(f, \"train\"), train_files), total=len(train_files)))\n",
    "            \n",
    "            # Process validation files\n",
    "            print(\"[INFO] Processing validation files...\")\n",
    "            list(tqdm(executor.map(lambda f: self.process_file(f, \"val\"), val_files), total=len(val_files)))\n",
    "            \n",
    "            # Process test files\n",
    "            print(\"[INFO] Processing test files...\")\n",
    "            list(tqdm(executor.map(lambda f: self.process_file(f, \"test\"), test_files), total=len(test_files)))\n",
    "        \n",
    "        return self.channel_matrices\n",
    "\n",
    "    def normalize_image(self, image):\n",
    "        \"\"\"\n",
    "        GPU-accelerated robust image normalization using percentile-based scaling.\n",
    "        \n",
    "        Normalizes images to 16-bit range (0-65535) using robust statistics to handle\n",
    "        outliers and varying illumination conditions common in microscopy data.\n",
    "        \n",
    "        Args:\n",
    "            image (np.ndarray): Input image array (any numeric dtype)\n",
    "            \n",
    "        Returns:\n",
    "            np.ndarray: Normalized image as uint16 in range [0, 65535]\n",
    "            \n",
    "        Algorithm:\n",
    "        1. Convert to float32 tensor for GPU computation\n",
    "        2. Calculate 0.01% and 99.99% percentiles as robust min/max\n",
    "        3. Scale linearly to 16-bit range\n",
    "        4. Clamp and convert back to uint16\n",
    "        \n",
    "        Note:\n",
    "            Uses TensorFlow Probability for efficient percentile computation on GPU.\n",
    "            Robust percentiles prevent outlier pixels from distorting normalization.\n",
    "        \"\"\"\n",
    "        with tf.device(self.device):\n",
    "            image_tf = tf.convert_to_tensor(image, dtype=tf.float32)\n",
    "            b_min = tfp.stats.percentile(image_tf, 0.0001 * 100)\n",
    "            b_max = tfp.stats.percentile(image_tf, 0.9999 * 100)\n",
    "            b_range = tf.maximum(b_max - b_min, 1e-7)  # Prevent division by zero\n",
    "            normalized = (image_tf - b_min) / b_range * 65535\n",
    "            return tf.cast(normalized, tf.uint16).numpy()\n",
    "\n",
    "\n",
    "    def piecewise_brighten(self, image, lower_factor=1.2, upper_factor=2.0, threshold=None):\n",
    "        \"\"\"\n",
    "        GPU-accelerated piecewise brightness enhancement for microscopy images.\n",
    "        \n",
    "        Applies differential brightness enhancement to improve contrast in both\n",
    "        dim and bright regions of microscopy images. Uses automatic thresholding\n",
    "        to separate intensity regions and apply appropriate enhancement factors.\n",
    "        \n",
    "        Args:\n",
    "            image (np.ndarray): Input image to enhance\n",
    "            lower_factor (float): Brightness multiplier for pixels below threshold\n",
    "            upper_factor (float): Brightness multiplier for pixels above threshold  \n",
    "            threshold (float, optional): Intensity threshold. If None, uses 99th percentile\n",
    "            \n",
    "        Returns:\n",
    "            np.ndarray: Enhanced image as uint16, clipped to valid range\n",
    "            \n",
    "        Algorithm:\n",
    "        1. Auto-threshold at 99th percentile if not specified\n",
    "        2. Apply lower_factor to dim pixels (< threshold)\n",
    "        3. Apply upper_factor to bright pixels (>= threshold)\n",
    "        4. Clip to valid 16-bit range and return\n",
    "        \n",
    "        Use Case:\n",
    "            Enhances fluorescence signal visibility while preserving detail in\n",
    "            both background and bright signal regions.\n",
    "        \"\"\"\n",
    "        with tf.device(self.device):\n",
    "            image_tf = tf.convert_to_tensor(image, dtype=tf.float32)\n",
    "        \n",
    "            # Auto-threshold at 99th percentile if not specified\n",
    "            if threshold is None:\n",
    "                threshold = tfp.stats.percentile(image_tf, 99)\n",
    "        \n",
    "            # Apply piecewise transformation\n",
    "            result = tf.where(\n",
    "                image_tf < threshold,\n",
    "                image_tf * lower_factor,\n",
    "                image_tf * upper_factor\n",
    "            )\n",
    "        \n",
    "            # Clip and convert back to uint16\n",
    "            return tf.clip_by_value(result, 0, 65535).numpy().astype(np.uint16)\n",
    "   \n",
    "\n",
    "    def generate_mask(self, img_norm):\n",
    "        \"\"\"\n",
    "        Generate binary mask identifying the largest connected region in the image.\n",
    "        \n",
    "        Creates a binary mask using Otsu's thresholding followed by connected component\n",
    "        analysis to identify and isolate the largest continuous region. Useful for\n",
    "        focusing analysis on primary biological structures.\n",
    "        \n",
    "        Args:\n",
    "            img_norm (np.ndarray): Normalized input image (2D array)\n",
    "            \n",
    "        Returns:\n",
    "            np.ndarray: Binary mask as uint8 (255=foreground, 0=background)\n",
    "            \n",
    "        Algorithm:\n",
    "        1. Apply Otsu's threshold to create initial binary mask\n",
    "        2. Perform connected component labeling\n",
    "        3. Identify largest connected component by pixel count\n",
    "        4. Create final mask containing only the largest component\n",
    "        \n",
    "        Note:\n",
    "            Assumes the largest connected component represents the main biological\n",
    "            structure of interest (e.g., cell culture, tissue section).\n",
    "        \"\"\"\n",
    "        threshold = threshold_otsu(img_norm)\n",
    "        binary_mask = img_norm <= threshold\n",
    "        labeled_mask, num_features = ndimage.label(binary_mask)\n",
    "        sizes = ndimage.sum(binary_mask, labeled_mask, range(num_features + 1))\n",
    "        largest_component = (labeled_mask == np.argmax(sizes))\n",
    "        return (largest_component * 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "    def extract_tiles(self, img_norm, final_mask, square_size=400, target_size=128):\n",
    "        \"\"\"\n",
    "        Extract standardized tiles around the centroid of a binary mask.\n",
    "        \n",
    "        Crops a square region centered on the mask centroid, then divides into\n",
    "        quadrant tiles and resizes to target dimensions. Provides consistent\n",
    "        spatial sampling for training deep learning models.\n",
    "        \n",
    "        Args:\n",
    "            img_norm (np.ndarray): Normalized source image (2D)\n",
    "            final_mask (np.ndarray): Binary mask defining region of interest\n",
    "            square_size (int): Size of square region to extract around centroid\n",
    "            target_size (int): Final tile size after resizing\n",
    "            \n",
    "        Returns:\n",
    "            list: List of resized tiles as numpy arrays, empty list if extraction fails\n",
    "            \n",
    "        Algorithm:\n",
    "        1. Calculate mask centroid using center of mass\n",
    "        2. Define square crop region centered on centroid\n",
    "        3. Handle boundary conditions (image edges)\n",
    "        4. Divide cropped region into 4 quadrant tiles\n",
    "        5. Resize each tile to target dimensions with anti-aliasing\n",
    "        \n",
    "        Error Handling:\n",
    "            Returns empty list if:\n",
    "            - Centroid calculation fails\n",
    "            - Crop boundaries are invalid\n",
    "            - Any tile is empty after cropping\n",
    "        \"\"\"\n",
    "        # Convert mask to binary if needed\n",
    "        if final_mask.dtype != bool:\n",
    "            final_mask = final_mask > 0\n",
    "    \n",
    "        # Get centroid coordinates\n",
    "        centroid_y, centroid_x = ndimage.center_of_mass(final_mask)\n",
    "        centroid_y, centroid_x = int(round(float(centroid_y))), int(round(float(centroid_x)))\n",
    "    \n",
    "        half_size = square_size // 2\n",
    "    \n",
    "        # Explicitly get image dimensions as integers\n",
    "        img_height, img_width = int(img_norm.shape[0]), int(img_norm.shape[1])\n",
    "    \n",
    "        # Calculate boundaries with explicit type conversion\n",
    "        y_min = max(0, int(centroid_y - half_size))\n",
    "        y_max = min(img_height, int(centroid_y + half_size))\n",
    "        x_min = max(0, int(centroid_x - half_size))\n",
    "        x_max = min(img_width, int(centroid_x + half_size))\n",
    "    \n",
    "        # Safety check for valid boundaries\n",
    "        if y_min >= y_max or x_min >= x_max:\n",
    "            print(f\"Warning: Invalid crop coordinates (y:{y_min}-{y_max}, x:{x_min}-{x_max})\")\n",
    "            return []\n",
    "    \n",
    "        # Proceed with cropping\n",
    "        cropped_region = img_norm[y_min:y_max, x_min:x_max]\n",
    "    \n",
    "        # Divide into quadrant tiles\n",
    "        mid_y, mid_x = cropped_region.shape[0] // 2, cropped_region.shape[1] // 2\n",
    "    \n",
    "        tiles = [\n",
    "            cropped_region[:mid_y, :mid_x],   # Top-left\n",
    "            cropped_region[:mid_y, mid_x:],   # Top-right\n",
    "            cropped_region[mid_y:, :mid_x],   # Bottom-left\n",
    "            cropped_region[mid_y:, mid_x:]    # Bottom-right\n",
    "        ]\n",
    "    \n",
    "        # Resize tiles to target dimensions\n",
    "        resized_tiles = []\n",
    "        for tile in tiles:\n",
    "            if tile.size > 0:  # Only process non-empty tiles\n",
    "                resized = resize(tile, (target_size, target_size),\n",
    "                           preserve_range=True, anti_aliasing=True)\n",
    "                resized_tiles.append(resized)\n",
    "    \n",
    "        return resized_tiles\n",
    "\n",
    "\n",
    "class cGANDataPipeline:\n",
    "    \"\"\"\n",
    "    Comprehensive data pipeline for conditional GAN training on microscopy images.\n",
    "    \n",
    "    Manages the complete data preprocessing workflow for multi-channel microscopy data,\n",
    "    creating aligned triplets of brightfield and fluorescence images, extracting tiles,\n",
    "    and preparing training batches for conditional GAN models.\n",
    "    \n",
    "    Key Features:\n",
    "    - Ensures perfect alignment between channels (ch1, ch2, ch3)\n",
    "    - Handles train/validation/test data splits\n",
    "    - Creates paired data for both generator and discriminator training\n",
    "    - Generates tiles from region-of-interest masks\n",
    "    - Saves preprocessed data in efficient batch format\n",
    "    \n",
    "    Attributes:\n",
    "        channel_matrices (dict): Organized file paths by channel\n",
    "        tile_size (int): Target size for extracted tiles\n",
    "        image_processor (ImageProcessor): Instance for image processing operations\n",
    "        val_split (float): Validation set proportion (deprecated - using organized splits)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, channel_matrices, image_processor, tile_size=128, val_split=0.2):\n",
    "        \"\"\"\n",
    "        Initialize the cGAN data pipeline.\n",
    "        \n",
    "        Args:\n",
    "            channel_matrices (dict): Organized file paths from ImageProcessor\n",
    "            image_processor (ImageProcessor): Instance for image processing\n",
    "            tile_size (int): Target tile size for model input\n",
    "            val_split (float): Validation split ratio (deprecated)\n",
    "        \"\"\"\n",
    "        self.channel_matrices = channel_matrices\n",
    "        self.tile_size = tile_size\n",
    "        self.image_processor = image_processor\n",
    "        self.val_split = val_split\n",
    "        self._prepare_datasets()\n",
    "\n",
    "\n",
    "    def _get_aligned_triplets(self, subset=\"train\"):\n",
    "        \"\"\"\n",
    "        Create aligned triplets of corresponding images across all three channels.\n",
    "        \n",
    "        Ensures that ch1 (dead), ch2 (alive), and ch3 (brightfield) images from the \n",
    "        same microscopy position and timepoint are properly matched for training.\n",
    "        Critical for maintaining correspondence between input and target images.\n",
    "        \n",
    "        Args:\n",
    "            subset (str): Data subset ('train', 'val', or 'test')\n",
    "            \n",
    "        Returns:\n",
    "            list: List of tuples (ch1_path, ch2_path, ch3_path) for aligned images\n",
    "            \n",
    "        Algorithm:\n",
    "        1. Find common position keys across all three channels\n",
    "        2. Sort files within each position by base filename (ignoring channel suffix)\n",
    "        3. Verify alignment by comparing base filenames\n",
    "        4. Create triplets only for perfectly aligned images\n",
    "        \n",
    "        Raises:\n",
    "            ValueError: If channel directories are missing for the subset\n",
    "            \n",
    "        Note:\n",
    "            Prints warnings for misaligned files but continues processing.\n",
    "            Alignment is critical - misaligned triplets would corrupt training.\n",
    "        \"\"\"\n",
    "        triplets = []\n",
    "        base_dir = os.path.join(\"channel_matrix\", subset)\n",
    "        ch1_dir = os.path.join(base_dir, \"ch1\")\n",
    "        ch2_dir = os.path.join(base_dir, \"ch2\")\n",
    "        ch3_dir = os.path.join(base_dir, \"ch3\")\n",
    "\n",
    "        # Verify all channel directories exist\n",
    "        if not all(os.path.exists(d) for d in [ch1_dir, ch2_dir, ch3_dir]):\n",
    "            raise ValueError(f\"Missing channel directories for subset {subset}\")\n",
    "\n",
    "        ch1_keys = set(os.listdir(ch1_dir))\n",
    "        ch2_keys = set(os.listdir(ch2_dir))\n",
    "        ch3_keys = set(os.listdir(ch3_dir))\n",
    "        common_keys = ch1_keys & ch2_keys & ch3_keys\n",
    "\n",
    "        for key in common_keys:\n",
    "            # Get files and sort by BASE filename (ignoring channel)\n",
    "            ch1_files = sorted(\n",
    "                [f for f in os.listdir(os.path.join(ch1_dir, key)) if f.endswith(\".tiff\")],\n",
    "                key=lambda x: x.split(\"-ch1\")[0]  \n",
    "            )\n",
    "            ch2_files = sorted(\n",
    "                [f for f in os.listdir(os.path.join(ch2_dir, key)) if f.endswith(\".tiff\")],\n",
    "                key=lambda x: x.split(\"-ch2\")[0]\n",
    "            )\n",
    "            ch3_files = sorted(\n",
    "                [f for f in os.listdir(os.path.join(ch3_dir, key)) if f.endswith(\".tiff\")],\n",
    "                key=lambda x: x.split(\"-ch3\")[0]\n",
    "            )\n",
    "\n",
    "            # Verify alignment after sorting\n",
    "            for i, (f1, f2, f3) in enumerate(zip(ch1_files, ch2_files, ch3_files)):\n",
    "                base1 = f1.split(\"-ch1\")[0]\n",
    "                base2 = f2.split(\"-ch2\")[0]\n",
    "                base3 = f3.split(\"-ch3\")[0]\n",
    "        \n",
    "                if base1 == base2 == base3:\n",
    "                    triplet = (\n",
    "                        os.path.join(ch1_dir, key, f1),\n",
    "                        os.path.join(ch2_dir, key, f2),\n",
    "                        os.path.join(ch3_dir, key, f3)\n",
    "                    )\n",
    "                    triplets.append(triplet)\n",
    "                else:\n",
    "                    print(f\"[WARNING] Mismatched base in {subset} set, key {key} index {i}: {base1} vs {base2} vs {base3}\")\n",
    "\n",
    "        print(f\"[INFO] Found {len(triplets)} aligned triplets in {subset} set\")\n",
    "        return triplets\n",
    "\n",
    "    def _process_triplet(self, ch3_path, ch1_path, ch2_path):\n",
    "        \"\"\"\n",
    "        Process a single aligned triplet of images into training-ready tiles.\n",
    "        \n",
    "        Loads, preprocesses, and extracts tiles from aligned microscopy images.\n",
    "        Creates data pairs for both generator training (brightfield → fluorescence)\n",
    "        and discriminator training (real vs. fake fluorescence pairs).\n",
    "        \n",
    "        Args:\n",
    "            ch3_path (str): Path to brightfield image (generator input)\n",
    "            ch1_path (str): Path to dead cell fluorescence image (target 1)\n",
    "            ch2_path (str): Path to alive cell fluorescence image (target 2)\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (generator_inputs, generator_targets_dead, generator_targets_alive, discriminator_real_pairs)\n",
    "            - generator_inputs: List of ch3 tiles for generator input\n",
    "            - generator_targets_dead: List of ch1 tiles for generator target\n",
    "            - generator_targets_alive: List of ch2 tiles for generator target  \n",
    "            - discriminator_real_pairs: List of (ch3, ch1/ch2) pairs for discriminator training\n",
    "            \n",
    "        Processing Pipeline:\n",
    "        1. Load raw images from all three channels\n",
    "        2. Apply brightness enhancement to fluorescence channels\n",
    "        3. Normalize all images to consistent intensity ranges\n",
    "        4. Generate binary mask from brightfield for ROI detection\n",
    "        5. Extract aligned tiles from all channels using the same mask\n",
    "        6. Prepare generator input/target pairs\n",
    "        7. Create discriminator real/fake training pairs\n",
    "        \n",
    "        Note:\n",
    "            Returns empty lists if tile extraction fails.\n",
    "            Randomly assigns real discriminator pairs between dead/alive channels.\n",
    "        \"\"\"\n",
    "\n",
    "        print(\"-----Inside _process_triplet------\")\n",
    "\n",
    "        # Load raw images from all channels\n",
    "        ch3_raw = np.array(Image.open(ch3_path))\n",
    "        ch1_raw = np.array(Image.open(ch1_path))\n",
    "        ch2_raw = np.array(Image.open(ch2_path))\n",
    "\n",
    "        # Apply brightness enhancement to fluorescence channels\n",
    "        ch1_img = self.image_processor.piecewise_brighten(ch1_raw, 0.8, 3.6)\n",
    "        ch2_img = self.image_processor.piecewise_brighten(ch2_raw, 0.8, 3.6)\n",
    "        \n",
    "        # Normalize all three channels to consistent ranges\n",
    "        ch1_img = self.image_processor.normalize_image(ch1_img)\n",
    "        ch2_img = self.image_processor.normalize_image(ch2_img)\n",
    "        ch3_img = self.image_processor.normalize_image(ch3_raw)\n",
    "        \n",
    "\n",
    "        # Generate binary mask from brightfield to focus on relevant regions\n",
    "        binary_mask = self.image_processor.generate_mask(ch3_img)\n",
    "\n",
    "        # Extract aligned tiles from all channels using the same mask\n",
    "        ch1_tiles = self.image_processor.extract_tiles(ch1_img, binary_mask)\n",
    "        ch2_tiles = self.image_processor.extract_tiles(ch2_img, binary_mask)\n",
    "        ch3_tiles = self.image_processor.extract_tiles(ch3_img, binary_mask)\n",
    "\n",
    "\n",
    "        if not ch3_tiles:\n",
    "            print(\"Warning: No tiles extracted.\")\n",
    "            return [], [], [], []\n",
    "\n",
    "        # Prepare data for both dead (ch1) and alive (ch2) generation tasks\n",
    "        generator_inputs = []         # ch3 image tiles (brightfield input)\n",
    "        generator_targets_dead = []   # ch1 tiles (ground truth for dead cell generation)\n",
    "        generator_targets_alive = []  # ch2 tiles (ground truth for alive cell generation)\n",
    "\n",
    "        discriminator_real_pairs = [] # List to store (ch3_tile, ch1_tile) or (ch3_tile, ch2_tile) for real pairs\n",
    "\n",
    "        for i in range(len(ch3_tiles)):\n",
    "            ch3 = np.expand_dims(ch3_tiles[i], axis=-1)  # Input to generator (brightfield)\n",
    "            ch1 = np.expand_dims(ch1_tiles[i], axis=-1)  # Dead fluorescence (target 1)\n",
    "            ch2 = np.expand_dims(ch2_tiles[i], axis=-1)  # Alive fluorescence (target 2)\n",
    "\n",
    "            # Generator training pairs: G(ch3) → ch1 or ch2\n",
    "            generator_inputs.append(ch3)\n",
    "            generator_targets_dead.append(ch1)\n",
    "            generator_targets_alive.append(ch2)\n",
    "\n",
    "            # Discriminator real pairs: randomly choose between dead/alive channels\n",
    "            if np.random.rand() > 0.5:\n",
    "                discriminator_real_pairs.append((ch3, ch1)) # (brightfield, dead_fluorescence)\n",
    "            else:\n",
    "                discriminator_real_pairs.append((ch3, ch2)) # (brightfield, alive_fluorescence)\n",
    "\n",
    "\n",
    "        return generator_inputs, generator_targets_dead, generator_targets_alive, discriminator_real_pairs\n",
    "\n",
    "     \n",
    "    \n",
    "    def _prepare_datasets(self, output_dir=\"tiles\", batch_size=24):\n",
    "        \"\"\"\n",
    "        Prepare all datasets (train/validation/test) by processing triplets into batches.\n",
    "        \n",
    "        High-level orchestrator that processes each subset by calling _process_subset.\n",
    "        Creates the complete preprocessed dataset structure for GAN training.\n",
    "        \n",
    "        Args:\n",
    "            output_dir (str): Base directory for saving processed tile batches\n",
    "            batch_size (int): Number of samples per saved batch file\n",
    "        \"\"\"\n",
    "        for subset in [\"train\", \"test\", \"val\"]:\n",
    "            self._process_subset(output_dir, batch_size, subset)\n",
    "\n",
    "            \n",
    "    def _process_subset(self, output_dir, batch_size, subset):\n",
    "        \"\"\"\n",
    "        Process a complete data subset into batched, normalized training files.\n",
    "        \n",
    "        Converts aligned image triplets into normalized tile batches suitable for\n",
    "        GAN training. Handles data normalization, concatenation for discriminator\n",
    "        inputs, and efficient batch-wise saving.\n",
    "        \n",
    "        Args:\n",
    "            output_dir (str): Base directory for saving processed tiles\n",
    "            batch_size (int): Number of samples per batch file\n",
    "            subset (str): Data subset to process ('train', 'val', 'test')\n",
    "            \n",
    "        Processing Workflow:\n",
    "        1. Get all aligned triplets for the subset\n",
    "        2. Process each triplet into tiles and training pairs  \n",
    "        3. Normalize data to [-1, 1] range for stable GAN training\n",
    "        4. Concatenate brightfield + fluorescence for discriminator inputs\n",
    "        5. Save data in batches when batch_size is reached\n",
    "        6. Log progress and data statistics\n",
    "        \n",
    "        Data Normalization:\n",
    "            Converts uint16 [0, 65535] → float32 [-1, 1] using formula:\n",
    "            normalized = (data / 32767.5) - 1.0\n",
    "            \n",
    "        File Structure:\n",
    "            - gen_inputs_{batch_idx}.npy: Generator inputs (brightfield tiles)\n",
    "            - gen_targets_dead_{batch_idx}.npy: Dead fluorescence targets\n",
    "            - gen_targets_alive_{batch_idx}.npy: Alive fluorescence targets  \n",
    "            - disc_inputs_real_{batch_idx}.npy: Concatenated real pairs for discriminator\n",
    "            - disc_targets_real_{batch_idx}.npy: Labels (all 1.0 for real data)\n",
    "        \"\"\"\n",
    "        subset_dir = os.path.join(output_dir, subset)\n",
    "        os.makedirs(subset_dir, exist_ok=True)\n",
    "    \n",
    "        # Get triplets for the specified subset\n",
    "        triplets = self._get_aligned_triplets(subset)\n",
    "\n",
    "        # Initialize batch accumulators\n",
    "        gen_inputs, gen_targets_dead, gen_targets_alive = [], [], []\n",
    "        disc_inputs_real_concatenated, disc_targets_real = [], [] # Renamed for clarity\n",
    "        file_index = 0\n",
    "\n",
    "        def normalize_to_float32(data):\n",
    "            \"\"\"\n",
    "            Normalize uint16 [0,65535] to float32 [-1,1] for stable GAN training.\n",
    "            \n",
    "            Args:\n",
    "                data (np.ndarray): Input data in uint16 range\n",
    "                \n",
    "            Returns:\n",
    "                np.ndarray: Normalized data in [-1,1] range as float32\n",
    "            \"\"\"\n",
    "            data = data.astype(np.float32)  # First convert to float32\n",
    "            return (data / 32767.5) - 1.0  # Then normalize to [-1,1]\n",
    "\n",
    "        for i, (ch1_path, ch2_path, ch3_path) in enumerate(tqdm(triplets, \n",
    "                                                          desc=f\"Processing {subset} triplets\", \n",
    "                                                          unit=\"triplet\")):\n",
    "\n",
    "            # Process triplet into tiles and training pairs\n",
    "            generator_inputs_batch, generator_targets_dead_batch, generator_targets_alive_batch, discriminator_real_pairs_batch = self._process_triplet(\n",
    "                ch3_path, ch1_path, ch2_path)\n",
    "\n",
    "\n",
    "            if not generator_inputs_batch:\n",
    "                print(f\"⚠️  Skipping empty tile result in {subset} set.\")\n",
    "                continue\n",
    "\n",
    "            # Normalize and accumulate generator data\n",
    "            gen_inputs.extend([normalize_to_float32(x) for x in generator_inputs_batch])\n",
    "            gen_targets_dead.extend([normalize_to_float32(x) for x in generator_targets_dead_batch])\n",
    "            gen_targets_alive.extend([normalize_to_float32(x) for x in generator_targets_alive_batch])\n",
    "\n",
    "\n",
    "            # Prepare discriminator real pairs by concatenating channels\n",
    "            for brightfield_tile, fluo_tile in discriminator_real_pairs_batch:\n",
    "                # Concatenate brightfield (ch3) with real fluorescence (ch1 or ch2)\n",
    "                # Both are (128, 128, 1), concatenating gives (128, 128, 2)\n",
    "                concatenated_input = np.concatenate([brightfield_tile, fluo_tile], axis=-1)\n",
    "                disc_inputs_real_concatenated.append(normalize_to_float32(concatenated_input))\n",
    "                disc_targets_real.append(1.0)  # Label = 1 (real)\n",
    "\n",
    "            # Save batch when ready or at end of triplets\n",
    "            if len(gen_inputs) >= batch_size or i == len(triplets) - 1:\n",
    "                np.save(os.path.join(subset_dir, f\"gen_inputs_{file_index}.npy\"), np.stack(gen_inputs))\n",
    "                np.save(os.path.join(subset_dir, f\"gen_targets_dead_{file_index}.npy\"), np.stack(gen_targets_dead))\n",
    "                np.save(os.path.join(subset_dir, f\"gen_targets_alive_{file_index}.npy\"), np.stack(gen_targets_alive))\n",
    "                np.save(os.path.join(subset_dir, f\"disc_inputs_real_{file_index}.npy\"), np.stack(disc_inputs_real_concatenated))\n",
    "                np.save(os.path.join(subset_dir, f\"disc_targets_real_{file_index}.npy\"), np.array(disc_targets_real))\n",
    "\n",
    "                # Log batch statistics periodically\n",
    "                if file_index % 100 == 0 or i == len(triplets) - 1:\n",
    "                    print(f\"[{subset} Batch {file_index}] Range check - \"\n",
    "                          f\"Gen inputs: [{gen_inputs[0].min():.3f}, {gen_inputs[0].max():.3f}] | \"\n",
    "                          f\"Disc inputs: [{disc_inputs_real_concatenated[0].min():.3f}, {disc_inputs_real_concatenated[0].max():.3f}]\")\n",
    "                    print(f\"[{subset} Batch {file_index}] Shape check - \"\n",
    "                          f\"Gen inputs shape: {np.stack(gen_inputs).shape} | \"\n",
    "                          f\"Disc inputs shape: {np.stack(disc_inputs_real_concatenated).shape}\")                \n",
    "\n",
    "                # Reset accumulators for next batch\n",
    "                gen_inputs, gen_targets_dead, gen_targets_alive = [], [], []\n",
    "                disc_inputs_real_concatenated, disc_targets_real = [], []\n",
    "                file_index += 1\n",
    "\n",
    "        print(f\"🎉 {subset} dataset preparation completed. All batches saved to:\", subset_dir)\n",
    "\n",
    "\n",
    "class TileDataLoader(tf.keras.utils.Sequence):\n",
    "    \"\"\"\n",
    "    Efficient data loader for preprocessed tile batches in GAN training.\n",
    "    \n",
    "    Implements Keras Sequence interface for memory-efficient loading of large\n",
    "    datasets. Uses memory mapping to avoid loading entire dataset into RAM\n",
    "    while providing fast access to individual batches during training.\n",
    "    \n",
    "    Key Features:\n",
    "    - Memory-mapped file loading for large datasets\n",
    "    - Automatic shuffling between epochs\n",
    "    - GPU/CPU device awareness  \n",
    "    - Comprehensive error handling\n",
    "    - Data shape and type validation\n",
    "    \n",
    "    Attributes:\n",
    "        data_dir (str): Directory containing preprocessed batch files\n",
    "        batch_size (int): Number of samples per batch (not used - batches are pre-sized)\n",
    "        shuffle (bool): Whether to shuffle batch order between epochs\n",
    "        file_indices (list): Sorted list of available batch file indices\n",
    "        device (str): Compute device for operations\n",
    "        sample_shapes (dict): Reference shapes for data validation\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_dir, batch_size=24, shuffle=True):\n",
    "        \"\"\"\n",
    "        Initialize the data loader with batch file discovery and validation.\n",
    "        \n",
    "        Args:\n",
    "            data_dir (str): Directory containing .npy batch files\n",
    "            batch_size (int): Target batch size (informational - actual size from files)\n",
    "            shuffle (bool): Whether to shuffle batch order between epochs\n",
    "            \n",
    "        Raises:\n",
    "            FileNotFoundError: If data_dir doesn't exist or contains no valid batches\n",
    "            ValueError: If batch files are corrupted or have inconsistent shapes\n",
    "        \"\"\"\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.file_indices = self._get_file_indices()\n",
    "        self.device = '/GPU:0' if gpus else '/CPU:0'\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "        # Verify first sample for shape validation\n",
    "        sample = self.__getitem__(0)\n",
    "        self.sample_shapes = {k: v.shape for k, v in sample.items()}\n",
    "        print(f\"Initialized DataLoader with {len(self.file_indices)} batches\")\n",
    "        print(f\"Sample shapes: {self.sample_shapes}\")\n",
    "\n",
    "    def _get_file_indices(self):\n",
    "        \"\"\"\n",
    "        Discover and validate available batch file indices in the data directory.\n",
    "        \n",
    "        Scans directory for files matching expected naming pattern and extracts\n",
    "        batch indices. Ensures all required file types are present for each index.\n",
    "        \n",
    "        Returns:\n",
    "            list: Sorted list of valid batch indices\n",
    "            \n",
    "        Raises:\n",
    "            ValueError: If no valid batch files found\n",
    "        \"\"\"\n",
    "        files = os.listdir(self.data_dir)\n",
    "        indices = set()\n",
    "        for f in files:\n",
    "            if f.startswith(\"gen_inputs_\"):\n",
    "                idx = f.split(\"_\")[-1].split(\".\")[0]\n",
    "                indices.add(int(idx))\n",
    "        \n",
    "        if not indices:\n",
    "            raise ValueError(f\"No valid batch files found in {self.data_dir}\")\n",
    "            \n",
    "        return sorted(indices)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the number of batches available for training.\"\"\"\n",
    "        return len(self.file_indices)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Load and return a single batch of training data.\n",
    "        \n",
    "        Uses memory mapping for efficient loading without keeping entire dataset\n",
    "        in memory. Loads all required data types for a complete training batch.\n",
    "        \n",
    "        Args:\n",
    "            index (int): Batch index to load\n",
    "            \n",
    "        Returns:\n",
    "            dict: Training batch containing:\n",
    "                - 'gen_input': Generator input data (brightfield tiles)\n",
    "                - 'gen_target_dead': Dead fluorescence targets  \n",
    "                - 'gen_target_alive': Alive fluorescence targets\n",
    "                - 'disc_input': Discriminator input (concatenated real pairs)\n",
    "                - 'disc_target': Discriminator targets (real labels)\n",
    "                \n",
    "        Raises:\n",
    "            Exception: If batch loading fails (file corruption, missing files, etc.)\n",
    "        \"\"\"\n",
    "        idx = self.file_indices[index]\n",
    "        \n",
    "        try:\n",
    "            # Memory-mapped loading for efficiency\n",
    "            data = {\n",
    "                \"gen_input\": np.load(os.path.join(self.data_dir, f\"gen_inputs_{idx}.npy\"), mmap_mode='r'),\n",
    "                \"gen_target_dead\": np.load(os.path.join(self.data_dir, f\"gen_targets_dead_{idx}.npy\"), mmap_mode='r'),\n",
    "                \"gen_target_alive\": np.load(os.path.join(self.data_dir, f\"gen_targets_alive_{idx}.npy\"), mmap_mode='r'),\n",
    "                \"disc_input\": np.load(os.path.join(self.data_dir, f\"disc_inputs_real_{idx}.npy\"), mmap_mode='r'),\n",
    "                \"disc_target\": np.load(os.path.join(self.data_dir, f\"disc_targets_real_{idx}.npy\"), mmap_mode='r').astype(np.float32)\n",
    "            }\n",
    "            \n",
    "            # Convert to array (loads into memory only when needed)\n",
    "            return {k: np.array(v) for k, v in data.items()}\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading batch {idx}: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Shuffle batch indices if shuffling is enabled. Called automatically by Keras.\"\"\"\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.file_indices)\n",
    "    \n",
    "\n",
    "class cGAN(keras.Model):\n",
    "    \"\"\"\n",
    "    Conditional Generative Adversarial Network (cGAN) implementation.\n",
    "    \n",
    "    Wraps generator and discriminator models with training metrics tracking.\n",
    "    Provides the foundation for the adversarial training process.\n",
    "    \n",
    "    Attributes:\n",
    "        generator: Generator model for creating fake images\n",
    "        discriminator: Discriminator model for classifying real/fake images  \n",
    "        gen_loss_tracker: Metric tracker for generator loss\n",
    "        disc_loss_tracker: Metric tracker for discriminator loss\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, generator, discriminator):\n",
    "        \"\"\"\n",
    "        Initialize the cGAN with generator and discriminator models.\n",
    "        \n",
    "        Args:\n",
    "            generator: Keras model that generates fake images from inputs\n",
    "            discriminator: Keras model that classifies real vs fake image pairs\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "        self.gen_loss_tracker = keras.metrics.Mean(name=\"generator_loss\")\n",
    "        self.disc_loss_tracker = keras.metrics.Mean(name=\"discriminator_loss\")\n",
    "\n",
    "\n",
    "class GANMonitor(keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    Training monitoring callback for GAN models.\n",
    "    \n",
    "    Provides visualization of training progress and automatic model checkpointing.\n",
    "    Generates sample images during training to monitor generator quality.\n",
    "    \n",
    "    Attributes:\n",
    "        num_img (int): Number of sample images to generate\n",
    "        latent_dim (int): Dimension of latent noise vector\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_img=4, latent_dim=256):\n",
    "        \"\"\"\n",
    "        Initialize the monitoring callback.\n",
    "        \n",
    "        Args:\n",
    "            num_img (int): Number of images to generate for monitoring\n",
    "            latent_dim (int): Latent vector dimension for noise generation\n",
    "        \"\"\"\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "        os.makedirs(\"training_progress\", exist_ok=True)\n",
    "        os.makedirs(\"saved_models\", exist_ok=True)\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        \"\"\"\n",
    "        Generate sample images and save models at epoch end.\n",
    "        \n",
    "        Creates visualization grids showing dead vs alive cell generation\n",
    "        quality and saves model checkpoints periodically.\n",
    "        \n",
    "        Args:\n",
    "            epoch (int): Current epoch number\n",
    "            logs (dict): Training metrics (unused)\n",
    "        \"\"\"\n",
    "        noise = tf.random.normal([self.num_img, self.latent_dim])\n",
    "        dead_labels = tf.zeros([self.num_img, 1], dtype=tf.int32)\n",
    "        alive_labels = tf.ones([self.num_img, 1], dtype=tf.int32)\n",
    "        \n",
    "        dead_images = self.model.generator([noise, dead_labels])\n",
    "        alive_images = self.model.generator([noise, alive_labels])\n",
    "        \n",
    "        combined = np.vstack([dead_images, alive_images])\n",
    "        combined = (combined * 127.5 + 127.5).astype(np.uint8)\n",
    "        \n",
    "        fig = plt.figure(figsize=(8, 8))\n",
    "        for i in range(2 * self.num_img):\n",
    "            plt.subplot(2, self.num_img, i+1)\n",
    "            plt.imshow(combined[i,:,:,0], cmap='gray')\n",
    "            plt.axis('off')\n",
    "            plt.title(\"Dead\" if i < self.num_img else \"Alive\")\n",
    "        \n",
    "        plt.savefig(f\"training_progress/epoch_{epoch+1}.png\")\n",
    "        plt.close()\n",
    "        \n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            self.model.generator.save(f\"saved_models/generator_epoch_{epoch+1}.h5\")\n",
    "            self.model.discriminator.save(f\"saved_models/discriminator_epoch_{epoch+1}.h5\")\n",
    "\n",
    "\n",
    "def verify_dtypes(inputs_dict, name=\"input\"):\n",
    "    \"\"\"\n",
    "    Comprehensive data type and validity verification for model inputs.\n",
    "    \n",
    "    Validates tensor dtypes, shapes, value ranges, and checks for NaN/Inf values.\n",
    "    Critical for debugging numerical issues in GAN training.\n",
    "    \n",
    "    Args:\n",
    "        inputs_dict (dict): Dictionary of tensors to verify\n",
    "        name (str): Descriptive name for logging context\n",
    "        \n",
    "    Raises:\n",
    "        AssertionError: If any tensor has wrong dtype or contains invalid values\n",
    "        \n",
    "    Checks performed:\n",
    "    - Ensures all tensors are float32 dtype\n",
    "    - Logs tensor shapes and value ranges  \n",
    "    - Detects NaN and Infinity values\n",
    "    - Provides detailed diagnostic output\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== {name} DType Verification ===\")\n",
    "    for key, tensor in inputs_dict.items():\n",
    "        dtype = tensor.dtype\n",
    "        shape = tensor.shape\n",
    "        min_val = tf.reduce_min(tensor).numpy()\n",
    "        max_val = tf.reduce_max(tensor).numpy()\n",
    "        print(f\"{key}: {dtype} | Shape: {shape} | Range: [{min_val:.4f}, {max_val:.4f}]\")\n",
    "        \n",
    "        # Assert float32 dtype\n",
    "        assert dtype == tf.float32, f\"{key} has wrong dtype: {dtype}\"\n",
    "        \n",
    "        # Check for NaN/Inf\n",
    "        assert not tf.reduce_any(tf.math.is_nan(tensor)), f\"NaN detected in {key}\"\n",
    "        assert not tf.reduce_any(tf.math.is_inf(tensor)), f\"Inf detected in {key}\"\n",
    "\n",
    "\n",
    "def plot_samples(inputs, targets, predictions, title=\"\"):\n",
    "    \"\"\"\n",
    "    Create visualization comparing inputs, targets, and model predictions.\n",
    "    \n",
    "    Generates a grid plot showing brightfield inputs, ground truth targets,\n",
    "    and model predictions for visual assessment of training progress.\n",
    "    \n",
    "    Args:\n",
    "        inputs (np.ndarray): Input images (brightfield)\n",
    "        targets (np.ndarray): Ground truth target images  \n",
    "        predictions (np.ndarray): Model-generated predictions\n",
    "        title (str): Plot title for context\n",
    "        \n",
    "    Display Layout:\n",
    "        Each row shows: [Input | Target | Prediction] for up to 3 samples\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for i in range(min(3, len(inputs))):\n",
    "        plt.subplot(3, 3, i*3+1)\n",
    "        plt.imshow(inputs[i,...,0], cmap='gray')\n",
    "        plt.title(\"Input\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(3, 3, i*3+2)\n",
    "        plt.imshow(targets[i,...,0], cmap='gray')\n",
    "        plt.title(\"Target\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(3, 3, i*3+3)\n",
    "        plt.imshow(predictions[i,...,0], cmap='gray')\n",
    "        plt.title(\"Prediction\")\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def train(generator, discriminator, gan, data_gen, epochs=250, verbose=2, plot_interval=2):\n",
    "    \"\"\"\n",
    "    Comprehensive training loop for Wasserstein GAN with Gradient Penalty (WGAN-GP).\n",
    "    \n",
    "    Implements adversarial training between generator and discriminator using WGAN-GP\n",
    "    objective with gradient penalty for stable training. Includes comprehensive\n",
    "    logging, validation monitoring, and model checkpointing.\n",
    "    \n",
    "    Args:\n",
    "        generator: Generator model to train\n",
    "        discriminator: Discriminator model to train  \n",
    "        gan: Combined GAN model (unused in this implementation)\n",
    "        data_gen: Data generator providing training batches\n",
    "        epochs (int): Number of training epochs\n",
    "        verbose (int): Verbosity level (0=silent, 1=every epoch, 2=every 2 epochs, 3=every 10 epochs)\n",
    "        plot_interval (int): Frequency of generating plots and sample images\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (trained_generator, trained_discriminator, training_history)\n",
    "        \n",
    "    Training Algorithm:\n",
    "    1. Discriminator Training:\n",
    "       - Generate fake samples from current generator\n",
    "       - Compute Wasserstein loss on real vs fake samples  \n",
    "       - Add gradient penalty for Lipschitz constraint\n",
    "       - Update discriminator parameters\n",
    "       \n",
    "    2. Generator Training:\n",
    "       - Generate fake samples \n",
    "       - Compute adversarial loss (fool discriminator)\n",
    "       - Add L1 reconstruction losses for both dead/alive targets\n",
    "       - Update generator parameters\n",
    "       \n",
    "    Key Features:\n",
    "    - WGAN-GP implementation with gradient penalty\n",
    "    - Dual-target generator training (dead + alive fluorescence)\n",
    "    - Comprehensive metric tracking and visualization\n",
    "    - Automatic model checkpointing\n",
    "    - Validation monitoring on fixed batch\n",
    "    - Gradient clipping for numerical stability\n",
    "    \n",
    "    Loss Components:\n",
    "    - Discriminator: Wasserstein loss + 10.0 * gradient_penalty\n",
    "    - Generator: 2.0 * L1_dead + 2.0 * L1_alive + 3.0 * adversarial_loss\n",
    "    \"\"\"\n",
    "    # ====================== INITIALIZATION ======================\n",
    "\n",
    "    # Optimizers with different learning rates for stability\n",
    "    g_opt = tf.keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5)\n",
    "    d_opt = tf.keras.optimizers.Adam(learning_rate=5e-5, beta_1=0.5)\n",
    "\n",
    "    # Fixed validation batch for consistent monitoring\n",
    "    val_loader = TileDataLoader(\"tiles/val\", batch_size=16)\n",
    "    val_batch = next(iter(val_loader))\n",
    "    val_input = val_batch[\"gen_input\"]\n",
    "    val_target_dead = val_batch[\"gen_target_dead\"]\n",
    "    val_target_alive = val_batch[\"gen_target_alive\"]\n",
    "\n",
    "    total_batches = 496  # Update with actual batch count\n",
    "    \n",
    "    # Create logging directory with timestamp\n",
    "    current_time = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    log_dir = f\"logs/{current_time}\"\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    \n",
    "    # Initialize comprehensive metric tracking\n",
    "    history = {\n",
    "        'd_loss': [],           # Total discriminator loss\n",
    "        'g_loss': [],           # Total generator loss  \n",
    "        'd_loss_real': [],      # Discriminator loss on real samples\n",
    "        'd_loss_fake': [],      # Discriminator loss on fake samples\n",
    "        'grad_penalty': [],     # Gradient penalty component\n",
    "        'l1_dead': [],          # L1 loss for dead fluorescence\n",
    "        'l1_alive': [],         # L1 loss for alive fluorescence\n",
    "        'g_loss_gan': [],       # Generator adversarial loss\n",
    "        'val_l1_dead': [],      # Validation L1 for dead\n",
    "        'val_l1_alive': []      # Validation L1 for alive\n",
    "    }\n",
    "    \n",
    "    # ====================== TRAINING LOOP ======================\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # Reset epoch metrics\n",
    "        epoch_metrics = {k: 0 for k in history.keys() if not k.startswith('val_')}\n",
    "        batch_count = 0\n",
    "        \n",
    "        for batch_idx in range(total_batches):    \n",
    "            batch = data_gen.__getitem__(batch_idx)\n",
    "            real_ch3 = batch[\"gen_input\"]\n",
    "            real_dead = batch[\"gen_target_dead\"]\n",
    "            real_alive = batch[\"gen_target_alive\"]\n",
    "            disc_real = batch[\"disc_input\"]\n",
    "\n",
    "            # ============ DISCRIMINATOR TRAINING ============\n",
    "            with tf.GradientTape() as d_tape:\n",
    "                # Generate fake samples (generator in inference mode)\n",
    "                fake_dead, fake_alive = generator(real_ch3, training=False)\n",
    "                fake_dead = tf.clip_by_value(fake_dead, -1.0, 1.0)\n",
    "\n",
    "                # Get discriminator scores for real and fake data\n",
    "                real_out = discriminator(disc_real)\n",
    "                fake_dead_concatenated_for_D = tf.keras.layers.concatenate([real_ch3, fake_dead], axis=-1)\n",
    "                fake_out_dead = discriminator(fake_dead_concatenated_for_D)\n",
    "\n",
    "                # Binary cross-entropy losses with label smoothing\n",
    "                d_loss_real = tf.reduce_mean(\n",
    "                    tf.keras.losses.binary_crossentropy(\n",
    "                        tf.ones_like(real_out) * 0.9,  # Label smoothing\n",
    "                        real_out,\n",
    "                        from_logits=True\n",
    "                    )\n",
    "                )\n",
    "                \n",
    "                d_loss_fake = tf.reduce_mean(\n",
    "                    tf.keras.losses.binary_crossentropy(\n",
    "                        tf.zeros_like(fake_out_dead) + 0.1,  # Label smoothing\n",
    "                        fake_out_dead,\n",
    "                        from_logits=True\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                # Wasserstein adversarial loss\n",
    "                d_loss_adversarial = tf.reduce_mean(fake_out_dead) - tf.reduce_mean(real_out)\n",
    "\n",
    "                # Gradient Penalty (WGAN-GP) for Lipschitz constraint\n",
    "                with tf.GradientTape() as gp_tape:\n",
    "                    # Create interpolated samples\n",
    "                    alpha_shape = tf.concat([\n",
    "                        [tf.shape(disc_real)[0]],\n",
    "                        [1] * (len(disc_real.shape) - 1)\n",
    "                    ], axis=0)\n",
    "                    alpha = tf.random.uniform(alpha_shape, 0., 1., dtype=tf.float32)\n",
    "                    interpolated = alpha * disc_real + (1 - alpha) * fake_dead_concatenated_for_D\n",
    "        \n",
    "                    # Watch interpolated samples for gradient computation\n",
    "                    gp_tape.watch(interpolated)\n",
    "                    crit_interpolated = discriminator(interpolated)\n",
    "            \n",
    "                # Compute gradient penalty\n",
    "                grads = gp_tape.gradient(crit_interpolated, [interpolated])[0]\n",
    "                grad_norms = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]))\n",
    "                grad_penalty = 10 * tf.reduce_mean(tf.square(grad_norms - 1.0)) # Lambda = 10.0\n",
    "\n",
    "                # Total discriminator loss\n",
    "                d_loss = d_loss_adversarial + grad_penalty\n",
    "\n",
    "            # Update discriminator with gradient clipping\n",
    "            d_grads = d_tape.gradient(d_loss, discriminator.trainable_variables)\n",
    "            d_grads = [tf.where(tf.math.is_nan(g), tf.zeros_like(g), g) for g in d_grads]\n",
    "            d_opt.apply_gradients(zip(d_grads, discriminator.trainable_variables))\n",
    "\n",
    "            # ============ GENERATOR TRAINING ============\n",
    "            with tf.GradientTape() as g_tape:\n",
    "                # Generate fake samples (generator in training mode)\n",
    "                fake_dead, fake_alive = generator(real_ch3, training=True)\n",
    "                fake_dead = tf.clip_by_value(fake_dead, -1.0, 1.0)\n",
    "                \n",
    "                # Prepare discriminator input for generator loss\n",
    "                fake_dead_concatenated_for_G = tf.keras.layers.concatenate([real_ch3, fake_dead], axis=-1)\n",
    "                fake_out_dead_for_G_loss = discriminator(fake_dead_concatenated_for_G)\n",
    "\n",
    "                # Generator adversarial loss (maximize discriminator score on fake)\n",
    "                g_loss_gan = -tf.reduce_mean(fake_out_dead_for_G_loss)\n",
    "\n",
    "                # Reconstruction losses for both dead and alive channels\n",
    "                l1_dead = tf.reduce_mean(tf.abs(real_dead - fake_dead))\n",
    "                l1_alive = tf.reduce_mean(tf.abs(real_alive - fake_alive))\n",
    "                \n",
    "                # Combined generator loss with weighting\n",
    "                g_loss = 2.0 * l1_dead + 2.0 * l1_alive + 3.0 * g_loss_gan\n",
    "\n",
    "            # Update generator with gradient clipping\n",
    "            g_grads = g_tape.gradient(g_loss, generator.trainable_variables)\n",
    "            g_grads = [tf.where(tf.math.is_nan(g), tf.zeros_like(g), g) for g in g_grads]\n",
    "            g_opt.apply_gradients(zip(g_grads, generator.trainable_variables))\n",
    "\n",
    "            # Accumulate batch metrics\n",
    "            metrics = {\n",
    "                'd_loss': d_loss,\n",
    "                'g_loss': g_loss,\n",
    "                'd_loss_real': d_loss_real,\n",
    "                'd_loss_fake': d_loss_fake,\n",
    "                'grad_penalty': grad_penalty,\n",
    "                'l1_dead': l1_dead,\n",
    "                'l1_alive': l1_alive,\n",
    "                'g_loss_gan': g_loss_gan\n",
    "            }\n",
    "            \n",
    "            for k, v in metrics.items():\n",
    "                epoch_metrics[k] += v\n",
    "            batch_count += 1\n",
    "\n",
    "        # Calculate epoch averages and update history\n",
    "        for k in epoch_metrics.keys():\n",
    "            epoch_metrics[k] /= batch_count\n",
    "            history[k].append(float(epoch_metrics[k]))\n",
    "\n",
    "        # Validation evaluation\n",
    "        val_pred_dead, val_pred_alive = generator(val_input, training=False)\n",
    "        history['val_l1_dead'].append(tf.reduce_mean(tf.abs(val_target_dead - val_pred_dead)).numpy())\n",
    "        history['val_l1_alive'].append(tf.reduce_mean(tf.abs(val_target_alive - val_pred_alive)).numpy())\n",
    "\n",
    "        # Generate validation samples for visualization\n",
    "        if epoch % plot_interval == 0:\n",
    "            plot_samples(\n",
    "                val_input[:3], \n",
    "                val_target_dead[:3], \n",
    "                val_pred_dead[:3],\n",
    "                title=f\"Epoch {epoch} Validation\"\n",
    "            )\n",
    "        \n",
    "        # ============ VERBOSE OUTPUT ============\n",
    "        if verbose == 1:  # Print every epoch\n",
    "            print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "            print(f\"D_loss: {epoch_metrics['d_loss']:.4f} (Real: {epoch_metrics['d_loss_real']:.4f}, Fake: {epoch_metrics['d_loss_fake']:.4f}, GP: {epoch_metrics['grad_penalty']:.4f})\")\n",
    "            print(f\"G_loss: {epoch_metrics['g_loss']:.4f} (L1: {epoch_metrics['l1_dead']+epoch_metrics['l1_alive']:.4f}, GAN: {epoch_metrics['g_loss_gan']:.4f})\")\n",
    "        elif verbose == 2:  # Print every 2 epochs\n",
    "            if (epoch + 1) % 2 == 0 or epoch == 0:\n",
    "                print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "                print(f\"D_loss: {epoch_metrics['d_loss']:.4f} (Real: {epoch_metrics['d_loss_real']:.4f}, Fake: {epoch_metrics['d_loss_fake']:.4f}, GP: {epoch_metrics['grad_penalty']:.4f})\")\n",
    "                print(f\"G_loss: {epoch_metrics['g_loss']:.4f} (L1: {epoch_metrics['l1_dead']+epoch_metrics['l1_alive']:.4f}, GAN: {epoch_metrics['g_loss_gan']:.4f})\")\n",
    "                print(f\"Val L1 Dead: {history['val_l1_dead'][-1]:.4f} | Alive: {history['val_l1_alive'][-1]:.4f}\")\n",
    "        elif verbose == 3:  # Print every 10 epochs\n",
    "            if (epoch + 1) % 10 == 0 or epoch == 0:\n",
    "                print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "                print(f\"D_loss: {epoch_metrics['d_loss']:.4f} (Real: {epoch_metrics['d_loss_real']:.4f}, Fake: {epoch_metrics['d_loss_fake']:.4f}, GP: {epoch_metrics['grad_penalty']:.4f})\")\n",
    "                print(f\"G_loss: {epoch_metrics['g_loss']:.4f} (L1: {epoch_metrics['l1_dead']+epoch_metrics['l1_alive']:.4f}, GAN: {epoch_metrics['g_loss_gan']:.4f})\")\n",
    "\n",
    "        # ============ PLOTTING ============\n",
    "        if (epoch + 1) % plot_interval == 0 or epoch == epochs - 1:\n",
    "            plt.figure(figsize=(15, 10))\n",
    "            \n",
    "            # Plot main losses\n",
    "            plt.subplot(2, 2, 1)\n",
    "            plt.plot(history['d_loss'], label='Discriminator Loss')\n",
    "            plt.plot(history['g_loss'], label='Generator Loss')\n",
    "            plt.title('Training Losses')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.legend()\n",
    "            \n",
    "            # Plot discriminator components\n",
    "            plt.subplot(2, 2, 2)\n",
    "            plt.plot(history['d_loss_real'], label='D Loss Real')\n",
    "            plt.plot(history['d_loss_fake'], label='D Loss Fake')\n",
    "            plt.plot(history['grad_penalty'], label='Gradient Penalty')\n",
    "            plt.title('Discriminator Loss Components')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.legend()\n",
    "            \n",
    "            # Plot generator components\n",
    "            plt.subplot(2, 2, 3)\n",
    "            plt.plot(history['l1_dead'], label='L1 Dead')\n",
    "            plt.plot(history['l1_alive'], label='L1 Alive')\n",
    "            plt.title('Generator Reconstruction Losses')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('L1')\n",
    "            plt.legend()\n",
    "            \n",
    "            # Plot GAN loss\n",
    "            plt.subplot(2, 2, 4)\n",
    "            plt.plot(history['g_loss_gan'], label='GAN Loss')\n",
    "            plt.title('Generator GAN Loss')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.legend()\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'{log_dir}/training_plot_epoch_{epoch+1}.png')\n",
    "            if verbose > 0:  # Only show plot if some verbosity is enabled\n",
    "                plt.show()\n",
    "            plt.close()\n",
    "\n",
    "        # Model checkpointing every 5 epochs\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            generator.save(f\"{log_dir}/generator_epoch{epoch+1}.h5\")\n",
    "            discriminator.save(f\"{log_dir}/discriminator_epoch{epoch+1}.h5\")\n",
    "\n",
    "    # Save comprehensive final plots\n",
    "    save_final_plots(history, log_dir)\n",
    "    \n",
    "    return generator, discriminator, history\n",
    "\n",
    "\n",
    "def save_final_plots(history, log_dir):\n",
    "    \"\"\"\n",
    "    Generate and save comprehensive final training visualization plots.\n",
    "    \n",
    "    Creates a detailed 6-panel visualization showing all aspects of GAN training\n",
    "    including loss components, reconstruction quality, and training dynamics.\n",
    "    \n",
    "    Args:\n",
    "        history (dict): Training history containing all tracked metrics\n",
    "        log_dir (str): Directory to save the final plots\n",
    "        \n",
    "    Plot Panels:\n",
    "    1. Main losses (D loss vs G loss)\n",
    "    2. Discriminator loss components (real, fake, gradient penalty)\n",
    "    3. Generator loss components (L1 dead, L1 alive, GAN loss)\n",
    "    4. Reconstruction losses comparison\n",
    "    5. Generator adversarial loss trend\n",
    "    6. Combined discriminator loss analysis\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(18, 12))\n",
    "    \n",
    "    # Main losses comparison\n",
    "    plt.subplot(2, 3, 1)\n",
    "    plt.plot(history['d_loss'], label='D Loss')\n",
    "    plt.plot(history['g_loss'], label='G Loss')\n",
    "    plt.title('Training Losses')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Discriminator loss breakdown\n",
    "    plt.subplot(2, 3, 2)\n",
    "    plt.plot(history['d_loss_real'], label='D Real')\n",
    "    plt.plot(history['d_loss_fake'], label='D Fake')\n",
    "    plt.plot(history['grad_penalty'], label='Gradient Penalty')\n",
    "    plt.title('Discriminator Loss Components')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Generator loss breakdown\n",
    "    plt.subplot(2, 3, 3)\n",
    "    plt.plot(history['l1_dead'], label='L1 Dead')\n",
    "    plt.plot(history['l1_alive'], label='L1 Alive')\n",
    "    plt.plot(history['g_loss_gan'], label='GAN Loss')\n",
    "    plt.title('Generator Loss Components')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Reconstruction quality comparison\n",
    "    plt.subplot(2, 3, 4)\n",
    "    plt.plot(history['l1_dead'], label='Dead')\n",
    "    plt.plot(history['l1_alive'], label='Alive')\n",
    "    plt.title('Reconstruction Losses')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Generator adversarial performance\n",
    "    plt.subplot(2, 3, 5)\n",
    "    plt.plot(history['g_loss_gan'], label='GAN Loss')\n",
    "    plt.title('Generator Adversarial Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Combined discriminator analysis\n",
    "    plt.subplot(2, 3, 6)\n",
    "    plt.plot([r + f for r, f in zip(history['d_loss_real'], history['d_loss_fake'])], \n",
    "             label='D Real+Fake')\n",
    "    plt.plot(history['grad_penalty'], label='Gradient Penalty')\n",
    "    plt.title('Discriminator Combined Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{log_dir}/final_training_plots.png')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def build_and_compile_models():\n",
    "    \"\"\"\n",
    "    Build and compile the complete cGAN model architecture.\n",
    "    \n",
    "    Constructs generator and discriminator models, configures their compilation\n",
    "    settings, and creates a combined GAN model for end-to-end training.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (generator, discriminator, gan) - All compiled and ready for training\n",
    "        \n",
    "    Model Architecture:\n",
    "    - Generator: U-Net style encoder-decoder with dual outputs (dead/alive)\n",
    "    - Discriminator: CNN classifier for real/fake image pair classification\n",
    "    - Combined GAN: End-to-end model linking generator output to discriminator input\n",
    "    \n",
    "    Compilation Settings:\n",
    "    - Optimizers: Adam with beta_1=0.5 (recommended for GAN training)\n",
    "    - Learning rates: 2e-4 for stability\n",
    "    - Loss functions: Configured for WGAN-GP training\n",
    "    - Loss weights: [2.0, 2.0, 1.0] for MSE_dead, MSE_alive, GAN_loss\n",
    "    \n",
    "    Note:\n",
    "        Discriminator is frozen during generator training phase via trainable=False.\n",
    "        Actual WGAN-GP losses are implemented manually in the training loop.\n",
    "    \"\"\"\n",
    "    # Build individual models\n",
    "    generator = build_generator()\n",
    "    discriminator = build_discriminator()\n",
    "\n",
    "    # Verify model dtypes for debugging\n",
    "    print(\"Generator input dtype:\", generator.input.dtype)\n",
    "    print(\"Discriminator input dtype:\", discriminator.input.dtype)\n",
    "\n",
    "    # Compile discriminator (loss is placeholder - WGAN-GP implemented manually)\n",
    "    discriminator.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5),\n",
    "        loss='mse',  # Placeholder for WGAN-GP manual implementation\n",
    "    )\n",
    "\n",
    "    # Create combined GAN model for generator training\n",
    "    discriminator.trainable = False  # Freeze during generator training\n",
    "\n",
    "    # Define GAN input and data flow\n",
    "    gan_input_brightfield = Input(shape=(128, 128, 1), dtype=tf.float32, name='gan_input_brightfield')\n",
    "\n",
    "    # Generator produces dual outputs\n",
    "    gen_dead, gen_alive = generator(gan_input_brightfield)\n",
    "\n",
    "    # Discriminator evaluates concatenated (brightfield, generated) pairs\n",
    "    discriminator_input_for_gan = concatenate([gan_input_brightfield, gen_dead], axis=-1)\n",
    "    gan_validity = discriminator(discriminator_input_for_gan)\n",
    "\n",
    "    # Combined model with multiple outputs\n",
    "    gan = Model(gan_input_brightfield, [gen_dead, gen_alive, gan_validity], name='gan_model')\n",
    "\n",
    "    # Compile GAN with weighted losses\n",
    "    gan.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5),\n",
    "        loss=['mse', 'mse', 'mse'],  # Placeholder losses\n",
    "        loss_weights=[2.0, 2.0, 1.0]  # MSE_dead, MSE_alive, GAN_loss weights\n",
    "    )\n",
    "    \n",
    "    return generator, discriminator, gan\n",
    "    \n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main execution pipeline for the complete cGAN training workflow.\n",
    "    \n",
    "    Orchestrates the entire process from raw image organization through\n",
    "    model training, including:\n",
    "    1. Image organization and train/val/test splitting\n",
    "    2. Dataset preprocessing and tile extraction\n",
    "    3. Model building and compilation\n",
    "    4. Training execution with monitoring\n",
    "    \n",
    "    Workflow:\n",
    "    - Initialize ImageProcessor with source image directory\n",
    "    - Organize images into channel-specific directory structure\n",
    "    - Create data pipeline for tile extraction and batch preparation\n",
    "    - Build and compile GAN models\n",
    "    - Execute training with comprehensive monitoring\n",
    "    \n",
    "    Configuration:\n",
    "    - Expects TIFF images in specified directory structure\n",
    "    - Uses 128x128 tiles for training\n",
    "    - Implements WGAN-GP training for 250 epochs\n",
    "    - Saves models and visualizations automatically\n",
    "    \n",
    "    Note:\n",
    "        Update image_path to point to your actual data directory.\n",
    "        Adjust training parameters (epochs, batch_size) as needed.\n",
    "    \"\"\"\n",
    "    # Initialize image processor with source directory\n",
    "    image_path = r\"YOUR_IMAGE_PATH\\Images\"\n",
    "    processor = ImageProcessor(image_path)\n",
    "    \n",
    "    # Step 1: Organize images into train/val/test splits\n",
    "    print(\"Organizing images...\")\n",
    "    channel_matrices = processor.organize_images()\n",
    "    \n",
    "    # Step 2: Prepare datasets with tile extraction and normalization\n",
    "    print(\"Preparing datasets...\")\n",
    "    data_pipeline = cGANDataPipeline(channel_matrices, processor)\n",
    "    \n",
    "    # Step 3: Build and compile models\n",
    "    print(\"Building models...\")\n",
    "    generator, discriminator, gan = build_and_compile_models()\n",
    "\n",
    "    # Step 4: Initialize data loader\n",
    "    data_gen = TileDataLoader(\"tiles/train\", batch_size=16)\n",
    "\n",
    "    # Verify data pipeline integrity\n",
    "    sample_batch = next(iter(data_gen))\n",
    "    for k, v in sample_batch.items():\n",
    "        print(f\"{k}: {v.dtype}\")\n",
    "\n",
    "    # Step 5: Execute training\n",
    "    trained_generator, trained_discriminator, history = train(\n",
    "         generator=generator,\n",
    "         discriminator=discriminator,\n",
    "         gan=gan,\n",
    "         data_gen=data_gen,\n",
    "         epochs=250,\n",
    "         verbose=2,\n",
    "         plot_interval=2\n",
    "    )\n",
    "\n",
    "    print(\"Training completed!\")\n",
    "    \n",
    "    # Optional: Save final models\n",
    "    # trained_generator.save(\"final_generator.h5\")\n",
    "    # trained_discriminator.save(\"final_discriminator.h5\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
